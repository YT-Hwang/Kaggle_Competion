{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/harupy/m5-baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T17:48:59.425429Z",
     "start_time": "2020-03-17T17:48:59.420444Z"
    }
   },
   "source": [
    "# Objective\n",
    "\n",
    "    - Make a baseline model that predict the validation (28 days).\n",
    "    - This competition has 2 stages, so the main objective is to make a model that can predict the demand for the next 28 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T18:15:42.367177Z",
     "start_time": "2020-03-17T18:15:41.243912Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "register_matplotlib_converters()\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T18:58:13.053811Z",
     "start_time": "2020-03-17T18:58:13.048810Z"
    }
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "\n",
    "def display(*dfs, head=True):\n",
    "    for df in dfs:\n",
    "        IPython.display.display(df.head() if head else df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T18:58:13.520917Z",
     "start_time": "2020-03-17T18:58:13.518916Z"
    }
   },
   "outputs": [],
   "source": [
    "def on_kaggle():\n",
    "    return \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T18:58:13.890002Z",
     "start_time": "2020-03-17T18:58:13.887011Z"
    }
   },
   "outputs": [],
   "source": [
    "if on_kaggle():\n",
    "    os.system(\"pip install --quiet mlflow_extend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T05:49:44.615330Z",
     "start_time": "2020-03-18T05:49:44.601326Z"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \n",
    "    '''\n",
    "    Reference:\n",
    "    https://towardsdatascience.com/how-to-learn-from-bigdata-files-on-low-memory-incremental-learning-d377282d38ff\n",
    "    '''\n",
    "    \n",
    "    numerics = [\"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T05:43:57.418738Z",
     "start_time": "2020-03-18T05:43:57.412736Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    INPUT_DIR = \"F:\\\\OneDrive - Georgia State University\\\\Data Science\\\\Competition\\\\Data\\\\M5_Forcasting_Accuracy\"\n",
    "    #INPUT_DIR = f\"{INPUT_DIR}\\\\M5_Forcasting_Accuracy\"\n",
    "\n",
    "    print(\"Reading files...\")\n",
    "\n",
    "    calendar = pd.read_csv(f\"{INPUT_DIR}/calendar.csv\").pipe(reduce_mem_usage)\n",
    "    sell_prices = pd.read_csv(f\"{INPUT_DIR}/sell_prices.csv\").pipe(reduce_mem_usage)\n",
    "\n",
    "    sales_train_val = pd.read_csv(f\"{INPUT_DIR}/sales_train_validation.csv\",).pipe(\n",
    "        reduce_mem_usage\n",
    "    )\n",
    "    submission = pd.read_csv(f\"{INPUT_DIR}/sample_submission.csv\").pipe(\n",
    "        reduce_mem_usage\n",
    "    )\n",
    "\n",
    "    print(\"calendar shape:\", calendar.shape)\n",
    "    print(\"sell_prices shape:\", sell_prices.shape)\n",
    "    print(\"sales_train_val shape:\", sales_train_val.shape)\n",
    "    print(\"submission shape:\", submission.shape)\n",
    "\n",
    "    # calendar shape: (1969, 14)\n",
    "    # sell_prices shape: (6841121, 4)\n",
    "    # sales_train_val shape: (30490, 1919)\n",
    "    # submission shape: (60980, 29)\n",
    "\n",
    "    return calendar, sell_prices, sales_train_val, submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T05:49:43.358594Z",
     "start_time": "2020-03-18T05:43:58.220919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n",
      "Mem. usage decreased to  0.12 Mb (41.9% reduction)\n",
      "Mem. usage decreased to 130.48 Mb (37.5% reduction)\n",
      "Mem. usage decreased to 95.00 Mb (78.7% reduction)\n",
      "Mem. usage decreased to  2.09 Mb (84.5% reduction)\n",
      "calendar shape: (1969, 14)\n",
      "sell_prices shape: (6841121, 4)\n",
      "sales_train_val shape: (30490, 1919)\n",
      "submission shape: (60980, 29)\n"
     ]
    }
   ],
   "source": [
    "calendar, sell_prices, sales_train_val, submission = read_data()\n",
    "\n",
    "NUM_ITEMS = sales_train_val.shape[0]  # 30490\n",
    "DAYS_PRED = submission.shape[1] - 1  # 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As @kaushal2896 suggested in this [comment](https://www.kaggle.com/harupy/m5-baseline#770558), encode the categorical columns before merging to prevent the notebook from crashing even with the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T05:49:53.703730Z",
     "start_time": "2020-03-18T05:49:49.317298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  0.08 Mb (36.9% reduction)\n",
      "Mem. usage decreased to 94.01 Mb (0.4% reduction)\n",
      "Mem. usage decreased to 45.67 Mb (41.7% reduction)\n"
     ]
    }
   ],
   "source": [
    "def encode_categorical(df, cols):\n",
    "    for col in cols:\n",
    "        # Leave NaN as it is.\n",
    "        le = LabelEncoder()\n",
    "        not_null = df[col][df[col].notnull()]\n",
    "        df[col] = pd.Series(le.fit_transform(not_null), index=not_null.index)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "calendar = encode_categorical(\n",
    "    calendar, [\"event_name_1\", \"event_type_1\", \"event_name_2\", \"event_type_2\"]\n",
    ").pipe(reduce_mem_usage)\n",
    "\n",
    "sales_train_val = encode_categorical(\n",
    "    sales_train_val, [\"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"],\n",
    ").pipe(reduce_mem_usage)\n",
    "\n",
    "sell_prices = encode_categorical(sell_prices, [\"item_id\", \"store_id\"]).pipe(\n",
    "    reduce_mem_usage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T05:49:54.543622Z",
     "start_time": "2020-03-18T05:49:54.527596Z"
    }
   },
   "outputs": [],
   "source": [
    "def melt(\n",
    "    sales_train_val, submission, nrows=55_000_000, verbose=True,\n",
    "):\n",
    "    # melt sales data, get it ready for training\n",
    "    id_columns = [\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"]\n",
    "\n",
    "    # get product table.\n",
    "    product = sales_train_val[id_columns]\n",
    "\n",
    "    sales_train_val = sales_train_val.melt(\n",
    "        id_vars=id_columns, var_name=\"d\", value_name=\"demand\",\n",
    "    )\n",
    "\n",
    "    sales_train_val = reduce_mem_usage(sales_train_val, verbose=False)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"melted\")\n",
    "        display(sales_train_val)\n",
    "\n",
    "    # separate test dataframes.\n",
    "    vals = submission[submission[\"id\"].str.endswith(\"validation\")]\n",
    "    evals = submission[submission[\"id\"].str.endswith(\"evaluation\")]\n",
    "\n",
    "    # change column names.\n",
    "    vals.columns = [\"id\"] + [f\"d_{d}\" for d in range(1914, 1914 + DAYS_PRED)]\n",
    "    evals.columns = [\"id\"] + [f\"d_{d}\" for d in range(1942, 1942 + DAYS_PRED)]\n",
    "\n",
    "    # merge with product table\n",
    "    evals[\"id\"] = evals[\"id\"].str.replace(\"_evaluation\", \"_validation\")\n",
    "    vals = vals.merge(product, how=\"left\", on=\"id\")\n",
    "    evals = evals.merge(product, how=\"left\", on=\"id\")\n",
    "    evals[\"id\"] = evals[\"id\"].str.replace(\"_validation\", \"_evaluation\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"validation\")\n",
    "        display(vals)\n",
    "\n",
    "        print(\"evaluation\")\n",
    "        display(evals)\n",
    "\n",
    "    vals = vals.melt(id_vars=id_columns, var_name=\"d\", value_name=\"demand\")\n",
    "    evals = evals.melt(id_vars=id_columns, var_name=\"d\", value_name=\"demand\")\n",
    "\n",
    "    sales_train_val[\"part\"] = \"train\"\n",
    "    vals[\"part\"] = \"validation\"\n",
    "    evals[\"part\"] = \"evaluation\"\n",
    "\n",
    "    data = pd.concat([sales_train_val, vals, evals], axis=0)\n",
    "\n",
    "    del sales_train_val, vals, evals\n",
    "\n",
    "    data = data.loc[nrows:]\n",
    "\n",
    "    # delete evaluation for now.\n",
    "    data = data[data[\"part\"] != \"evaluation\"]\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    if verbose:\n",
    "        print(\"data\")\n",
    "        display(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_d(df):\n",
    "    return df[\"d\"].str.extract(r\"d_(\\d+)\").astype(np.int16)\n",
    "\n",
    "\n",
    "def merge_calendar(data, calendar):\n",
    "    calendar = calendar.drop([\"weekday\", \"wday\", \"month\", \"year\"], axis=1)\n",
    "    return data.merge(calendar, how=\"left\", on=\"d\").assign(d=extract_d)\n",
    "\n",
    "\n",
    "def merge_sell_prices(data, sell_prices):\n",
    "    return data.merge(sell_prices, how=\"left\", on=[\"store_id\", \"item_id\", \"wm_yr_wk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T05:52:08.797812Z",
     "start_time": "2020-03-18T05:49:55.313775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "melted\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id  item_id  dept_id  cat_id  store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_validation     1437        3       1         0   \n",
       "1  HOBBIES_1_002_CA_1_validation     1438        3       1         0   \n",
       "2  HOBBIES_1_003_CA_1_validation     1439        3       1         0   \n",
       "3  HOBBIES_1_004_CA_1_validation     1440        3       1         0   \n",
       "4  HOBBIES_1_005_CA_1_validation     1441        3       1         0   \n",
       "\n",
       "   state_id    d  demand  \n",
       "0         0  d_1       0  \n",
       "1         0  d_1       0  \n",
       "2         0  d_1       0  \n",
       "3         0  d_1       0  \n",
       "4         0  d_1       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>d_1914</th>\n",
       "      <th>d_1915</th>\n",
       "      <th>d_1916</th>\n",
       "      <th>d_1917</th>\n",
       "      <th>d_1918</th>\n",
       "      <th>d_1919</th>\n",
       "      <th>d_1920</th>\n",
       "      <th>d_1921</th>\n",
       "      <th>d_1922</th>\n",
       "      <th>d_1923</th>\n",
       "      <th>d_1924</th>\n",
       "      <th>d_1925</th>\n",
       "      <th>d_1926</th>\n",
       "      <th>d_1927</th>\n",
       "      <th>d_1928</th>\n",
       "      <th>d_1929</th>\n",
       "      <th>d_1930</th>\n",
       "      <th>d_1931</th>\n",
       "      <th>d_1932</th>\n",
       "      <th>d_1933</th>\n",
       "      <th>d_1934</th>\n",
       "      <th>d_1935</th>\n",
       "      <th>d_1936</th>\n",
       "      <th>d_1937</th>\n",
       "      <th>d_1938</th>\n",
       "      <th>d_1939</th>\n",
       "      <th>d_1940</th>\n",
       "      <th>d_1941</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id  d_1914  d_1915  d_1916  d_1917  d_1918  \\\n",
       "0  HOBBIES_1_001_CA_1_validation       0       0       0       0       0   \n",
       "1  HOBBIES_1_002_CA_1_validation       0       0       0       0       0   \n",
       "2  HOBBIES_1_003_CA_1_validation       0       0       0       0       0   \n",
       "3  HOBBIES_1_004_CA_1_validation       0       0       0       0       0   \n",
       "4  HOBBIES_1_005_CA_1_validation       0       0       0       0       0   \n",
       "\n",
       "   d_1919  d_1920  d_1921  d_1922  d_1923  d_1924  d_1925  d_1926  d_1927  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   d_1928  d_1929  d_1930  d_1931  d_1932  d_1933  d_1934  d_1935  d_1936  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   d_1937  d_1938  d_1939  d_1940  d_1941  item_id  dept_id  cat_id  store_id  \\\n",
       "0       0       0       0       0       0     1437        3       1         0   \n",
       "1       0       0       0       0       0     1438        3       1         0   \n",
       "2       0       0       0       0       0     1439        3       1         0   \n",
       "3       0       0       0       0       0     1440        3       1         0   \n",
       "4       0       0       0       0       0     1441        3       1         0   \n",
       "\n",
       "   state_id  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>d_1942</th>\n",
       "      <th>d_1943</th>\n",
       "      <th>d_1944</th>\n",
       "      <th>d_1945</th>\n",
       "      <th>d_1946</th>\n",
       "      <th>d_1947</th>\n",
       "      <th>d_1948</th>\n",
       "      <th>d_1949</th>\n",
       "      <th>d_1950</th>\n",
       "      <th>d_1951</th>\n",
       "      <th>d_1952</th>\n",
       "      <th>d_1953</th>\n",
       "      <th>d_1954</th>\n",
       "      <th>d_1955</th>\n",
       "      <th>d_1956</th>\n",
       "      <th>d_1957</th>\n",
       "      <th>d_1958</th>\n",
       "      <th>d_1959</th>\n",
       "      <th>d_1960</th>\n",
       "      <th>d_1961</th>\n",
       "      <th>d_1962</th>\n",
       "      <th>d_1963</th>\n",
       "      <th>d_1964</th>\n",
       "      <th>d_1965</th>\n",
       "      <th>d_1966</th>\n",
       "      <th>d_1967</th>\n",
       "      <th>d_1968</th>\n",
       "      <th>d_1969</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id  d_1942  d_1943  d_1944  d_1945  d_1946  \\\n",
       "0  HOBBIES_1_001_CA_1_evaluation       0       0       0       0       0   \n",
       "1  HOBBIES_1_002_CA_1_evaluation       0       0       0       0       0   \n",
       "2  HOBBIES_1_003_CA_1_evaluation       0       0       0       0       0   \n",
       "3  HOBBIES_1_004_CA_1_evaluation       0       0       0       0       0   \n",
       "4  HOBBIES_1_005_CA_1_evaluation       0       0       0       0       0   \n",
       "\n",
       "   d_1947  d_1948  d_1949  d_1950  d_1951  d_1952  d_1953  d_1954  d_1955  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   d_1956  d_1957  d_1958  d_1959  d_1960  d_1961  d_1962  d_1963  d_1964  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   d_1965  d_1966  d_1967  d_1968  d_1969  item_id  dept_id  cat_id  store_id  \\\n",
       "0       0       0       0       0       0     1437        3       1         0   \n",
       "1       0       0       0       0       0     1438        3       1         0   \n",
       "2       0       0       0       0       0     1439        3       1         0   \n",
       "3       0       0       0       0       0     1440        3       1         0   \n",
       "4       0       0       0       0       0     1441        3       1         0   \n",
       "\n",
       "   state_id  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>demand</th>\n",
       "      <th>part</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27500000</th>\n",
       "      <td>HOUSEHOLD_1_514_WI_3_validation</td>\n",
       "      <td>2506</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>d_902</td>\n",
       "      <td>16</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27500001</th>\n",
       "      <td>HOUSEHOLD_1_515_WI_3_validation</td>\n",
       "      <td>2507</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>d_902</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27500002</th>\n",
       "      <td>HOUSEHOLD_1_516_WI_3_validation</td>\n",
       "      <td>2508</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>d_902</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27500003</th>\n",
       "      <td>HOUSEHOLD_1_517_WI_3_validation</td>\n",
       "      <td>2509</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>d_902</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27500004</th>\n",
       "      <td>HOUSEHOLD_1_518_WI_3_validation</td>\n",
       "      <td>2510</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>d_902</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id  item_id  dept_id  cat_id  store_id  \\\n",
       "27500000  HOUSEHOLD_1_514_WI_3_validation     2506        5       2         9   \n",
       "27500001  HOUSEHOLD_1_515_WI_3_validation     2507        5       2         9   \n",
       "27500002  HOUSEHOLD_1_516_WI_3_validation     2508        5       2         9   \n",
       "27500003  HOUSEHOLD_1_517_WI_3_validation     2509        5       2         9   \n",
       "27500004  HOUSEHOLD_1_518_WI_3_validation     2510        5       2         9   \n",
       "\n",
       "          state_id      d  demand   part  \n",
       "27500000         2  d_902      16  train  \n",
       "27500001         2  d_902       1  train  \n",
       "27500002         2  d_902       1  train  \n",
       "27500003         2  d_902       1  train  \n",
       "27500004         2  d_902       0  train  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1722.17 Mb (0.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "data = melt(sales_train_val, submission, nrows=27_500_000)\n",
    "del sales_train_val\n",
    "gc.collect()\n",
    "\n",
    "data = merge_calendar(data, calendar)\n",
    "del calendar\n",
    "gc.collect()\n",
    "\n",
    "data = merge_sell_prices(data, sell_prices)\n",
    "del sell_prices\n",
    "gc.collect()\n",
    "\n",
    "data = reduce_mem_usage(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T05:52:08.878830Z",
     "start_time": "2020-03-18T05:52:08.859826Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_demand_features(df):\n",
    "    for diff in [0, 1, 2]:\n",
    "        shift = DAYS_PRED + diff\n",
    "        df[f\"shift_t{shift}\"] = df.groupby([\"id\"])[\"demand\"].transform(\n",
    "            lambda x: x.shift(shift)\n",
    "        )\n",
    "\n",
    "    for size in [7, 30, 60, 90, 180]:\n",
    "        df[f\"rolling_std_t{size}\"] = df.groupby([\"id\"])[\"demand\"].transform(\n",
    "            lambda x: x.shift(DAYS_PRED).rolling(size).std()\n",
    "        )\n",
    "\n",
    "    for size in [7, 30, 60, 90, 180]:\n",
    "        df[f\"rolling_mean_t{size}\"] = df.groupby([\"id\"])[\"demand\"].transform(\n",
    "            lambda x: x.shift(DAYS_PRED).rolling(size).mean()\n",
    "        )\n",
    "\n",
    "    df[\"rolling_skew_t30\"] = df.groupby([\"id\"])[\"demand\"].transform(\n",
    "        lambda x: x.shift(DAYS_PRED).rolling(30).skew()\n",
    "    )\n",
    "    df[\"rolling_kurt_t30\"] = df.groupby([\"id\"])[\"demand\"].transform(\n",
    "        lambda x: x.shift(DAYS_PRED).rolling(30).kurt()\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_price_features(df):\n",
    "    df[\"shift_price_t1\"] = df.groupby([\"id\"])[\"sell_price\"].transform(\n",
    "        lambda x: x.shift(1)\n",
    "    )\n",
    "    df[\"price_change_t1\"] = (df[\"shift_price_t1\"] - df[\"sell_price\"]) / (\n",
    "        df[\"shift_price_t1\"]\n",
    "    )\n",
    "    df[\"rolling_price_max_t365\"] = df.groupby([\"id\"])[\"sell_price\"].transform(\n",
    "        lambda x: x.shift(1).rolling(365).max()\n",
    "    )\n",
    "    df[\"price_change_t365\"] = (df[\"rolling_price_max_t365\"] - df[\"sell_price\"]) / (\n",
    "        df[\"rolling_price_max_t365\"]\n",
    "    )\n",
    "\n",
    "    df[\"rolling_price_std_t7\"] = df.groupby([\"id\"])[\"sell_price\"].transform(\n",
    "        lambda x: x.rolling(7).std()\n",
    "    )\n",
    "    df[\"rolling_price_std_t30\"] = df.groupby([\"id\"])[\"sell_price\"].transform(\n",
    "        lambda x: x.rolling(30).std()\n",
    "    )\n",
    "    return df.drop([\"rolling_price_max_t365\", \"shift_price_t1\"], axis=1)\n",
    "\n",
    "\n",
    "def add_time_features(df, dt_col):\n",
    "    df[dt_col] = pd.to_datetime(df[dt_col])\n",
    "    attrs = [\n",
    "        \"year\",\n",
    "        \"quarter\",\n",
    "        \"month\",\n",
    "        \"week\",\n",
    "        \"day\",\n",
    "        \"dayofweek\",\n",
    "        \"is_year_end\",\n",
    "        \"is_year_start\",\n",
    "        \"is_quarter_end\",\n",
    "        \"is_quarter_start\",\n",
    "        \"is_month_end\",\n",
    "        \"is_month_start\",\n",
    "    ]\n",
    "\n",
    "    for attr in attrs:\n",
    "        dtype = np.int16 if attr == \"year\" else np.int8\n",
    "        df[attr] = getattr(df[dt_col].dt, attr).astype(dtype)\n",
    "\n",
    "    df[\"is_weekend\"] = df[\"dayofweek\"].isin([5, 6]).astype(np.int8)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-18T05:50:38.154Z"
    }
   },
   "outputs": [],
   "source": [
    "data = add_demand_features(data).pipe(reduce_mem_usage)\n",
    "data = add_price_features(data).pipe(reduce_mem_usage)\n",
    "dt_col = \"date\"\n",
    "data = add_time_features(data, dt_col).pipe(reduce_mem_usage)\n",
    "data = data.sort_values(\"date\")\n",
    "\n",
    "print(\"start date:\", data[dt_col].min())\n",
    "print(\"end date:\", data[dt_col].max())\n",
    "print(\"data shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-18T05:50:38.330Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_cv_indices(cv, X, y, dt_col, lw=10):\n",
    "    n_splits = cv.get_n_splits()\n",
    "    _, ax = plt.subplots(figsize=(20, n_splits))\n",
    "\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(\n",
    "            X[dt_col],\n",
    "            [ii + 0.5] * len(indices),\n",
    "            c=indices,\n",
    "            marker=\"_\",\n",
    "            lw=lw,\n",
    "            cmap=plt.cm.coolwarm,\n",
    "            vmin=-0.2,\n",
    "            vmax=1.2,\n",
    "        )\n",
    "\n",
    "    # Formatting\n",
    "    MIDDLE = 15\n",
    "    LARGE = 20\n",
    "    ax.set_xlabel(\"Datetime\", fontsize=LARGE)\n",
    "    ax.set_xlim([X[dt_col].min(), X[dt_col].max()])\n",
    "    ax.set_ylabel(\"CV iteration\", fontsize=LARGE)\n",
    "    ax.set_yticks(np.arange(n_splits) + 0.5)\n",
    "    ax.set_yticklabels(list(range(n_splits)))\n",
    "    ax.invert_yaxis()\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=MIDDLE)\n",
    "    ax.set_title(\"{}\".format(type(cv).__name__), fontsize=LARGE)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-18T05:50:38.514Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomTimeSeriesSplitter:\n",
    "    def __init__(self, n_splits=5, train_days=80, test_days=20, day_col=\"d\"):\n",
    "        self.n_splits = n_splits\n",
    "        self.train_days = train_days\n",
    "        self.test_days = test_days\n",
    "        self.day_col = day_col\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        SEC_IN_DAY = 3600 * 24\n",
    "        sec = (X[self.day_col] - X[self.day_col].iloc[0]) * SEC_IN_DAY\n",
    "        duration = sec.max()\n",
    "\n",
    "        train_sec = self.train_days * SEC_IN_DAY\n",
    "        test_sec = self.test_days * SEC_IN_DAY\n",
    "        total_sec = test_sec + train_sec\n",
    "\n",
    "        if self.n_splits == 1:\n",
    "            train_start = duration - total_sec\n",
    "            train_end = train_start + train_sec\n",
    "\n",
    "            train_mask = (sec >= train_start) & (sec < train_end)\n",
    "            test_mask = sec >= train_end\n",
    "\n",
    "            yield sec[train_mask].index.values, sec[test_mask].index.values\n",
    "\n",
    "        else:\n",
    "            # step = (duration - total_sec) / (self.n_splits - 1)\n",
    "            step = DAYS_PRED * SEC_IN_DAY\n",
    "\n",
    "            for idx in range(self.n_splits):\n",
    "                # train_start = idx * step\n",
    "                shift = (self.n_splits - (idx + 1)) * step\n",
    "                train_start = duration - total_sec - shift\n",
    "                train_end = train_start + train_sec\n",
    "                test_end = train_end + test_sec\n",
    "\n",
    "                train_mask = (sec > train_start) & (sec <= train_end)\n",
    "\n",
    "                if idx == self.n_splits - 1:\n",
    "                    test_mask = sec > train_end\n",
    "                else:\n",
    "                    test_mask = (sec > train_end) & (sec <= test_end)\n",
    "\n",
    "                yield sec[train_mask].index.values, sec[test_mask].index.values\n",
    "\n",
    "    def get_n_splits(self):\n",
    "        return self.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-18T05:50:38.682Z"
    }
   },
   "outputs": [],
   "source": [
    "day_col = \"d\"\n",
    "cv_params = {\n",
    "    \"n_splits\": 2,\n",
    "    \"train_days\": 365 * 2,\n",
    "    \"test_days\": DAYS_PRED,\n",
    "    \"day_col\": day_col,\n",
    "}\n",
    "cv = CustomTimeSeriesSplitter(**cv_params)\n",
    "# Plotting all the points takes long time.\n",
    "plot_cv_indices(\n",
    "    cv, data.iloc[::1000][[day_col, dt_col]].reset_index(drop=True), None, dt_col\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-18T05:50:38.850Z"
    }
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"item_id\",\n",
    "    \"dept_id\",\n",
    "    \"cat_id\",\n",
    "    \"store_id\",\n",
    "    \"state_id\",\n",
    "    \"event_name_1\",\n",
    "    \"event_type_1\",\n",
    "    \"event_name_2\",\n",
    "    \"event_type_2\",\n",
    "    \"snap_CA\",\n",
    "    \"snap_TX\",\n",
    "    \"snap_WI\",\n",
    "    \"sell_price\",\n",
    "    # demand features.\n",
    "    \"shift_t28\",\n",
    "    \"shift_t29\",\n",
    "    \"shift_t30\",\n",
    "    \"rolling_std_t7\",\n",
    "    \"rolling_std_t30\",\n",
    "    \"rolling_std_t60\",\n",
    "    \"rolling_std_t90\",\n",
    "    \"rolling_std_t180\",\n",
    "    \"rolling_mean_t7\",\n",
    "    \"rolling_mean_t30\",\n",
    "    \"rolling_mean_t60\",\n",
    "    \"rolling_mean_t90\",\n",
    "    \"rolling_mean_t180\",\n",
    "    \"rolling_skew_t30\",\n",
    "    \"rolling_kurt_t30\",\n",
    "    # price features\n",
    "    \"price_change_t1\",\n",
    "    \"price_change_t365\",\n",
    "    \"rolling_price_std_t7\",\n",
    "    \"rolling_price_std_t30\",\n",
    "    # time features.\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"week\",\n",
    "    \"day\",\n",
    "    \"dayofweek\",\n",
    "    \"is_year_end\",\n",
    "    \"is_year_start\",\n",
    "    \"is_quarter_end\",\n",
    "    \"is_quarter_start\",\n",
    "    \"is_month_end\",\n",
    "    \"is_month_start\",\n",
    "    \"is_weekend\",\n",
    "]\n",
    "\n",
    "# prepare training and test data.\n",
    "# 2011-01-29 ~ 2016-04-24 : d_1    ~ d_1913\n",
    "# 2016-04-25 ~ 2016-05-22 : d_1914 ~ d_1941 (public)\n",
    "# 2016-05-23 ~ 2016-06-19 : d_1942 ~ d_1969 (private)\n",
    "\n",
    "mask = data[\"date\"] <= \"2016-04-24\"\n",
    "\n",
    "# Attach \"d\" to X_train for cross validation.\n",
    "X_train = data[mask][[day_col] + features].reset_index(drop=True)\n",
    "y_train = data[mask][\"demand\"].reset_index(drop=True)\n",
    "X_test = data[~mask][features].reset_index(drop=True)\n",
    "\n",
    "# keep these two columns to use later.\n",
    "id_date = data[~mask][[\"id\", \"date\"]].reset_index(drop=True)\n",
    "\n",
    "del data\n",
    "gc.collect()\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-18T05:50:39.042Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_lgb(bst_params, fit_params, X, y, cv, drop_when_train=None):\n",
    "    models = []\n",
    "\n",
    "    if drop_when_train is None:\n",
    "        drop_when_train = []\n",
    "\n",
    "    for idx_fold, (idx_trn, idx_val) in enumerate(cv.split(X, y)):\n",
    "        print(f\"\\n---------- Fold: ({idx_fold + 1} / {cv.get_n_splits()}) ----------\\n\")\n",
    "\n",
    "        X_trn, X_val = X.iloc[idx_trn], X.iloc[idx_val]\n",
    "        y_trn, y_val = y.iloc[idx_trn], y.iloc[idx_val]\n",
    "        train_set = lgb.Dataset(X_trn.drop(drop_when_train, axis=1), label=y_trn)\n",
    "        val_set = lgb.Dataset(X_val.drop(drop_when_train, axis=1), label=y_val)\n",
    "\n",
    "        model = lgb.train(\n",
    "            bst_params,\n",
    "            train_set,\n",
    "            valid_sets=[train_set, val_set],\n",
    "            valid_names=[\"train\", \"valid\"],\n",
    "            **fit_params,\n",
    "        )\n",
    "        models.append(model)\n",
    "\n",
    "        del idx_trn, idx_val, X_trn, X_val, y_trn, y_val\n",
    "        gc.collect()\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-18T05:50:39.235Z"
    }
   },
   "outputs": [],
   "source": [
    "bst_params = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"metric\": \"rmse\",\n",
    "    \"objective\": \"regression\",\n",
    "    \"n_jobs\": -1,\n",
    "    \"seed\": 42,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"bagging_fraction\": 0.75,\n",
    "    \"bagging_freq\": 10,\n",
    "    \"colsample_bytree\": 0.75,\n",
    "}\n",
    "\n",
    "fit_params = {\n",
    "    \"num_boost_round\": 100_000,\n",
    "    \"early_stopping_rounds\": 50,\n",
    "    \"verbose_eval\": 100,\n",
    "}\n",
    "\n",
    "models = train_lgb(\n",
    "    bst_params, fit_params, X_train, y_train, cv, drop_when_train=[day_col]\n",
    ")\n",
    "\n",
    "del X_train, y_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-18T05:50:39.402Z"
    }
   },
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-18T05:50:39.570Z"
    }
   },
   "outputs": [],
   "source": [
    "imp_type = \"gain\"\n",
    "importances = np.zeros(X_test.shape[1])\n",
    "preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "for model in models:\n",
    "    preds += model.predict(X_test)\n",
    "    importances += model.feature_importance(imp_type)\n",
    "\n",
    "preds = preds / cv.get_n_splits()\n",
    "importances = importances / cv.get_n_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-18T05:50:39.754Z"
    }
   },
   "outputs": [],
   "source": [
    "from mlflow_extend import mlflow, plotting as mplt\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params_flatten({\"bst\": bst_params, \"fit\": fit_params, \"cv\": cv_params})\n",
    "\n",
    "\n",
    "features = models[0].feature_name()\n",
    "_ = mplt.feature_importance(features, importances, imp_type, limit=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-18T05:50:39.938Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_submission(test, submission):\n",
    "    preds = test[[\"id\", \"date\", \"demand\"]]\n",
    "    preds = preds.pivot(index=\"id\", columns=\"date\", values=\"demand\").reset_index()\n",
    "    preds.columns = [\"id\"] + [\"F\" + str(d + 1) for d in range(DAYS_PRED)]\n",
    "\n",
    "    evals = submission[submission[\"id\"].str.endswith(\"evaluation\")]\n",
    "    vals = submission[[\"id\"]].merge(preds, how=\"inner\", on=\"id\")\n",
    "    final = pd.concat([vals, evals])\n",
    "\n",
    "    assert final.drop(\"id\", axis=1).isnull().sum().sum() == 0\n",
    "    assert final[\"id\"].equals(submission[\"id\"])\n",
    "\n",
    "    final.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-18T05:50:40.122Z"
    }
   },
   "outputs": [],
   "source": [
    "make_submission(id_date.assign(demand=preds), submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
